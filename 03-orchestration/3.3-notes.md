# First Prefect Flow and Basics

## Use cases with MLflow
- Normal for Model Accuracy to decay over time (called Drift)
- To avoid this, regularly retrain model over time and push to production
	- Want to have the tools to retrain on a schedule and output model to proper location

Recall: orchestration.py
	- Move mlflow startup to main
	- Turn __main__ into main()

- Importing prefect; just from prefect import flow, task
	- Adds more logs
	- Add @flow to main
		- 2.0 will have more flexibility to which code to add to task
	- Add @task to add_features()
		- Adding this makes the function a future so you have to add .result() to function call
	- Can see task run created and completed in logs

- Can raise ValueError() in task
	- Will see task run failed in Prefect logs

- Can run Prefect server with just 'prefect orion start' in bash
	- Dashboard will be at localhost:4200
	- Can see Prefect flow runs even though we haven't been running the server
		- Prefect logs this data just from the function calls in Python
		- Even without server, @flow and @task, Prefect updates with API
- Go to Prefect > Flow Runs
	- Can see logs of failed run we failed on purpose	
	- Can click on radar plot (not interesting as there's only 3 tasks)
		- Basically just graph of execution

- Go back to prefect_flow.py, turn rest of training functions into tasks and run

- Prefect does not always play nice with MLflow
	- Prefect uses a "Concurrent task runner"
		- Say you have 3 tasks, independent of each other
			- Prefect will start the tasks asynchronously
		- So for flows, the flow_runner is set to ConcurrentTaskRunner by default
		- So with MLflow, with these inserts happening concurrently collide, so you need SequentialTaskRunner
	- Set @flow(task_runner=SequentialTaskRunner)
		- ConcurrentTaskRunner is faster and don't have to worry about concurrency
	- Tasks are the smallest unit for Prefect
		- This is why we want to break code into the smallest convenient functions, for observability
	- Go back to radar plot for latest Prefect run
		- Will see the functions run as Tasks
		- As you pass data between tasks, you will see more concentric circles with data dependencies annotated
		- E.g: Make X_train and X_val and pass to add_features (make this function a task)
			- Can see read_dataframe() passed data to add_features() on outer circle
	- More tasks mean more task run data in Prefect for each run
	- Caching: If a task was ran previously, you can cache it for the same day

- Back to main()
	- Can add safeguarding by checking input type
		- E.g. train_path: str='./data...'
	- What if we called main() with invalid parameters?
		- def main(x: int)
		- Pass main("1a")
		- Fails with error, " Flow run... received invalid parameters and is marked as failed"
	- Can use more complex data types like Pandas DataFrames with pydantic

- Summary:
	- Modularized functions for flow and tasks
	- Just need to give main or function a @flow
	- Prefect flow can take in Prefect or Python code, just need to call .result()
		- E.g. add_features(...).result()
	- Lets you make conditions
		- if X_train.shape[0] = 0; don't run further
	- By changing a function into task you get observability and logs
	- Can see all logs in Prefect Orion. Don't need to run server to get logs
