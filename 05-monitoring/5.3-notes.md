# 5.3 - Creating a prediction service and simulating traffic
- Will implement online monitoring and batch monitoring

- Let's observe how monitoring and prediction service look like
- Under 05-monitoring/prediction_service
	- Same as what Alexey made but saves to DB and sends to monitoring service
	- See app.py
		- Loading existing model, and use MongoDB client.
		- Use prediction function at /predict
			- At the end, save to DB and save to evidently

- Can see evidently examples; 05-monitoring/evidently_service/examples
	- Under evidently_service/app.py
		- See iterate(), shows how exactly we calculate metrics
			- We need window size because we there are metrics that cannot be calculated on top of individual events
				- Need to collect a bunch of events to calculate these (e.g. data drift)
			- Then send this data to prometheus

## Simulating Production service
- Run `docker compose up`
- Run send_data.py
	- Short script. We get the second dataset we downloaded (for testing model usage)
	- Create target.csv for writing, go through dataset row-by-row, and preprocess the data.
		- Get ride ID, calculate duration, write id and duration on each row
	- Send data to prediction service (so to localhost:9696/predict)
	- Waits 1 second between

## Testing
- Send data, wait for a while, and see what it looks like in MongoDB
- Create jupyter notebook; import pymongo and create MongoClient
	- See docker-compose.yml to see the Mongo port (URI: mongodb://localhost:27018)
		- Get DB at 'prediction_service'
			- Use this to create collection at 'data'
	- Make list of all data from collection
	- See structure of data and data[0]

