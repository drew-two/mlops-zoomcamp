# MLflow in practice

Consider three different scenarios:
1. A single data scientist participating in an ML competition
2. A cross-functional team with one data scientist working on an ML model
3. Multiple data scientists working on ML models

All have different environments.
	1. Doesn't need remote model server. No collaboration and no need for model store because there's no production
	2. Does have need to share information, but can run it locally. Not clear if model registry can be remotely or locally
	3. Needs remote server for collaboration. May need model registry if Ops handles model deployments

## Configuring MLflow
- Backend store
	- local filesystem (same directory if no DB specified)
	- SQLAlchemy compatible DB (e.g. SQLite), enables model registry
- Artifacts store
	- local filesystem (same directory if no DB specified)
	- remote (e.g. S3 bucket)
- Tracking server
	- no tracking server (fine for scenario 1)
	- localhost (fine for scenario 2)
	- remote (needed for team for DS) 
