# MLflow in practice

Consider three different scenarios:
1. A single data scientist participating in an ML competition
2. A cross-functional team with one data scientist working on an ML model
3. Multiple data scientists working on ML models

All have different environments.
	1. Doesn't need remote model server. No collaboration and no need for model store because there's no production
	2. Does have need to share information, but can run it locally. Not clear if model registry can be remotely or locally
	3. Needs remote server for collaboration. May need model registry if Ops handles model deployments

## Configuring MLflow
- Backend store
	- local filesystem (same directory if no DB specified)
	- SQLAlchemy compatible DB (e.g. SQLite), enables model registry
- Artifacts store
	- local filesystem (same directory if no DB specified)
	- remote (e.g. S3 bucket)
- Tracking server
	- no tracking server (fine for scenario 1)
	- localhost (fine for scenario 2)
	- remote (needed for team for DS) 

## Scenario 1
- If you don't specify MLflow store it uses the local ./mlruns directory
	- Doesn't actually make this until you call list_experiments()
	- Will return this local directory with get_tracking_uri()
- Creates meta.yaml file for each experiment:
	- set_experiment() creates if inexistent
	- Contains:
		- artifact_location: (filesystem path or uri)
		- experiment_id
		- lifecycle_stage
		- name
- Trains logreg on Iris dataset
	- Example for parameters
	- Ignore that it's predicting on training data
 	- Then log model to path (./models)
- Under each experiment folder (numbered integers going up from 0)
	- Each has a random folder name for each run
		- Has metrics folder - one file for each with just the file
		- Has params folder - same setup
		- MLflow tags folder - same setup
		- Has artifacts/models folders
			- Saves various model types
- Access model registry
	- Has MlflowException
		- No backend store set so no model registry
- Access runs in the UI (localhost:5000)
	- MUST be run in same folder where the proper respective "mlruns" folder is
		- We were running in 02-experiment-tracking/running-mlflow-examples/ so ./mlruns is there

## DELETE MLRUNS FOLDER BETWEEN SCENARIOS

## Scenario 2
- Cross-functional team (team with different roles)
	- ML engineer has to interact with frontend, backend, product manager etc
		- Need to share progress of model, how it's built etc
	- Fine if tracking server is local
		- Can see updates of long training runs in real time
		- Can see results before run finishes
	- Backend store needs DB (we use sqlite)
	- Artifacts store: local filesystem (cloud would be useful too)
- Launch mlflow server with DB and default artifact root
	- First thing mlflow does is create DB
- Set tracking uri with http://localhost:5000
	- (Can also call with sqlite address)
	- Calling list_experiments() we can see the correct directories
		- Can verify these exist in explorer
- Can see artifacts URI is under ./artifacts_local/
	- Metadata is not here though
		- It is under local DB
- Accessing model registry
	- Works this time
	- No registered models
	- Register the model!
		- Gets run_id and specifies experiment_id=1
		- Register model with uri "runs:/{run_id}/models"
			- Call it "iris-classifier"
	- Model registry successful
- * May need to delete cookies to see mlflow ui after restarting server*
- Going to my-experiment-1/<run>
	- Can see params like normal
	- Can't register model in UI cause it was already registered 
			
## Scenario 3
- Multiple data scientists so we want remote server and artifacts store
