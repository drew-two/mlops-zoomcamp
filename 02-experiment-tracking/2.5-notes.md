# Model Registry

## Motivation
- ML engineer has finished model. Sends you model in email 
	- What has changed?
	- Should I update the hyperparameters?
	- Do we need preprocessing?
	- What are the versions needed?
- Maybe you want to retrain this model or examine. But you don't have the code or metadata
	- If you're **lucky**, the ML engineer has stored this data in something like mlflow

Recall: We saw how to log models, parameters, metrics, and data to mlflow server
	- Saved all our runs to mlflow
	- Eventually some models are ready for production. Save these to mlflow **Model Registry**
		- So, when Ops needs to see which models to pushed to prod, they can check Model Registry
		- All production-ready models should be here
	- From here, models can be split to staging, production, etc. And archive if you need to rollback
	- **Only** holds models. Needs to be complimented with some CI/CD

Check best models
- Best: 6.3 rmse
	- ~ 3 min train
	- 9MB size
- Second best: 6.7 rmse
	- 3.6s train
	- Gradient boosting regressor
	- 115.4 KB
- Third best: 6.95 rmse 
	- 7 min train
	- 460 MB (huge!)

More complex models tend to take longer to train and predict
	- So, we take the second best model.

## Registering Models
- Hit **Register Model** button on an Experiment > Run > Artifacts
	- Create New Model
		- nyc-taxi-regressor
	- Button disappears and gives link to registered model
- Registering new model: Can create new name or use the same one.

Go to Model registry:
- See the model list for each project (e.g. nyc-taxi-regressor)
	- **Add description**
	- Below you can see all the available versions for the model.
- For each model:
	- Useful to add tags (e.g. model type, optimizer, creator, sprint etc)

Can transition between stages:
	- Set to Staging now
	- From here, deployment engineer will check the models and see which will promoted to production.

## Using model from registry
Go to 02-experiment-tracking/model-registry.ipynb
- Use same db uri
- Can use client.model to run functions with:
	- model version
	- models
	- tags
	- experiments
	- List, search, create, get, delete all of these

Say we are trying to see for a given experiment, which are the best trials
- client.search_runs(
	- runs = client.search_runs(
    		experiment_ids='1',
    		filter_string="metrics.rmse < 7",
    		run_view_type=ViewType.ACTIVE_ONLY,
    		max_results=5,
	  	order_by=["metrics.rmse ASC"]
	  )
		- Need:
			- Experiment ID
			- What to filter (tags)
			- What to order by
	- Can loop over this "runs" variable and print rmse id, rmse, really any tags/params in the experiment list 

## Promoting model from code
- Set tracking URI like normal
- Get run ID and model uri
	- URI is "runs:/{run_id}/model"
	- Get Run Id from "runs" variable
- Use register_model object
	- Can see under model nyc-taxi-regressor, there should be a new version
- Can iterate over versions and check metadata

- Can transition stages with client.transition_model_version_stage()
	- Need model name and version
	- Set 'stage' (None, Staging, Production, Archive)

- Can update models with client.update_model_version()
	- Need name and version
	- Can update metadata. Ex:
		- description=f"The model version {model_version} was transitioned to {new_stage} on {date}"

## Promoting staging models
- Might want to test Staging models, and archive old Production model
	1. Load test dataset (NYC Green Taxi March 2021)
	2. Get old pickled DictVectorizer and load it 
		a. Do NOT fit or fit_transform, just transform
	3. Make prediction using current Staging and Production models
		a. Load models
		b. Predict on March data
		c. Compare rmse

Get artifacts with download_artifacts() and open DV with pickle
- Create X_test with preprocessing, get y_test just by target values

Test models and time with %time before function call
- Lecture demo result: Staging model was slower and worse (used small sklearn model, we never made that)
- My results: Staging was a bit faster with same results

If you want to promote the new Staging model:
	- Call client.transition_model_version_stage()
	- Need model name and version
	- Set new stage ("Production")
	- archive_existing_versions=True (sets last Production model to archive)

Would be useful to log promotion. To version descriptions, add date archived and date promoted for the two models.
